Notes from Introduction to MongoDB from Nuri Halperin

you can put config in a mongod.conf file and use mongod -f [configfile.conf]

this file looks like

#comment describing line
dbpath=/example/db

logpath=/example/mongo.log



installing mongo as a service


// Install as service
mongod [options] --install

net start mongodb

mongo shell - for connecting to mongo via commandline
if its on local + default host you can connect with no options by typing "mongo" on the command line

====================
MONGO SHELL COMMANDS
====================

show dbs 							- list databases
db 									- show current database
use [dbName] 						- switch to database [dbName]
help								- show list of commands
db.foo.save({prop: value,...})		- save object to collection foo



Replica Sets 
============

Primary DB
Secondary DB (1 or more)
Arbiter DB (optional)

ALL writes go to primary, primary replicates this data onto secondaries.
Any writes to a secondary will fail, these are read only instances
If the primary fails, one of the secondaries will take over and become the primary
if one of the secondary fails, other secondaries or the primary will be able to handle all reads/writes

primary fails => an "election" is held
votes from over half of the total number of servers are required to make a new server a secondary. 
This means you cannot have just 1 primary and 1 secondary, as if primary goes down secondary would not get over 50% of votes.
You want an odd number of machines in the farm

Arbiters don't actually store any data, they are just used to break ties in elections. 
Arbiter's will never vote for themselves
They are something you can add in to bump you number of machines from even up to an odd.


You can set up three servers on your own machine so long as you use different ports. 
These will all need their own data locations on disk

in production of course these would all run on separate machines


use the --replSet option to tell an instance that they are part of a set

start "a" mongod --dbpath ./db1 --port 30000 --replSet "replicaSetDemo"
start "b" mongod --dbpath ./db2 --port 40000 --replSet "replicaSetDemo"
start "c" mongod --dbpath ./db3 --port 50000 --replSet "replicaSetDemo"

you still need more to tell these who is primary etc

you can connect to one of these with

mongo --port 30000

we're now connected to "a" via the mongo shell

we can now specify a config object. Below is a minimal example

const demoConfig = 
{
	"_id": "replicaSetDemo",
	"members": [
		{
			"_id": 0,
			"host": "localhost: 30000",
			"priority": 10 //gets more votes in an election - with no others having priority guarantees this will become primary
		},
		{
			"_id": 1,
			"host": "localhost: 40000",
		},
		{
			"_id": 2,
			"host": "localhost: 50000",
			"arbiterOnly": true
		},
	]
}

now to use this config and start the pool
rs.initiate(demoConfig) //rs stands for replicaSet

if the shell is showing
>	  							- it means server is just one server
replicaSetDemo:STARTUP>			- it means server is part of replicaSetDemo set, and set is starting up
replicaSetDemo:PRIMARY>			- server is part of replicaSetDemo set, and this server is the Primary


secondaries (slaves) need to be told its ok to accept reads. this can be done when connecting or by typing
db.setSlaveOk();


you can check replSet status with rs.help()


===========
MONGO SHELL
===========


Your application will communicate with the mongod server - look up files, save files

additionally the shell can be used to do the same things

in the shell you can write JS scripts - the shell is a JS interpreter
this could be a file loaded by the shell and executed or typed into the shell as is


you can write admin scripts 
- could have an admin script to reset data to a specific state etc
- could check status of document
- can check status of replsets etc

you can run the shell without opening it e.g just run a single script without opening whole shell console. This is really useful for tasks run as services/ on schedules

mongo server1/admin --eval "db.runCommand({logRotate: 1})" // rotate log file to new one so it doesn't get too big - could be scheduled daily

mongo server1 myTask.js

we can remain in the shell (e.g to see results/status) by using --shell

mongo server1 myTask.js --shell

printjson() -- prints result of command as JSON


mongo localhost/admin --eval "printjson(db.runCommand({logRotate: 1}))"
> {ok: 1}


script:

var userCount = function(){
	var count = db.Users.count();
	var entry = {_id: Date(), n: count};
	db.UserCountHistory.save(entry);
	print("Today's count: " + entry.n);
}

userCount();

we can call this with
mongo userCount.js


script safer.js
DB.prototype.dropDatabase = function() {
	print("dropDatabase is forbidden")
}

db.dropDatabase = DB.prototype.dropDatabase

mongo safer.js --shell
>db.dropDatabase();



you can use an external editor (e.g vs code) to define functions when scripting, rather than when doing it from the console/shell

this is done with set EDITOR="path-to-editor.exe"

then say you do 
myFunction = function(){
	///...
}

edit myFunction  - this will open myFunction in vscode for editing, so we can fix any issues - save it, then you can invoke the updated function


run a script from a file when you are in the mogno shell
load("filename.js"); - thats it


Running scripts each time someone enters the shell
.mongorc.js
- save this is C:/users/jessica
then any code in this file will be called when opening shell

these can be circumvented with mongo --norc

common strategy would be to disable dropdb and shutdownserver 



mongo uses memory-mapped files
pretending all info is existing and available to it whenever needed
the OS handles loading the actual file from disk from the memory mapped file


BSON - how is data formatted?

BSON = binary JSON
designed to be 
- Lightweight
- Traversable
- Efficient

this + memory mapping makes it very efficient to move from application data to disk and back


Saving Data rules:
#1 A document must have an _id field.

this is the only rule
document max size is 16mb


=====================
saving data via shell
=====================


show collections
>

db.foo.save({_id: 1, x:10}) // save this object to collection foo

db.foo.find()
> {"_id": 1, "x": 10}

show collections
>foo
>system.indexes

db.system.indexes.find
>{"v": 1, "key: {"_id: 1} //...}

_id can be int, number, string, date or complex object. Only invalid type is array


insert - Only insert document if document with this ID does not already exist

db.foo.insert({_id: 1, data: foo})
db.foo.insert({_id: 1, data: bar}) // returns error - duplicate ID 

by contrast - save would just blindly overwrite

insert could be used to prevent double-submission of forms etc, providing we are supplying the id. - for example we could use email as key


if id isn't provided, insert works same as save

When updating, always use update instead of save
aside from not having to manually read => update => write, it also will cause concurrency issues between the load and save.

update() is atomic within a document. Two concurrently issued update commands will be executed sequentially

db.foo.update(query, update, options);

options - can specify to update one, many, or upsert (insert if no doc matches query)

if options is omitted mongo will update just 1 doc and no upsert


update has operators e.g $inc so we don't have to lookup existing value to increment

db.foo.updatE({_id: 1}, {$inc: {x: 1}); // increment field x by 1



update operators
$inc - increment - {$inc: {x: 1}} //increment property x by 1
$set - set - {$set: {y: 2}} // set property y to 2
$unset - remvove field  - requires blank param e.g {$unset: {y: ""}} // to unset property y
$rename  - {$rename: {"naem", "name}} // rename "naem" property to "name"
$push - {$push: {arr: "foo"}} // pushes string "foo" to array arr - works even if arr does not exist
$addToSet - {$addToSet {arr: "foo"}} // pushes to array, but only if "foo" is not in the array concurrently
$pull - ${$pull: {arr: "foo"}} // remove all elements "foo" from the array
$pop - ${$pop: {arr: 1}} // remove element from end of array
$pop(inverse) - ${$pop: {arr: -1}} // remove elemnt from front of arrray - pop is safe on an empty array. Will leave empty array in place


===============
Multiple Update
===============

db.foo.update({}, ${push: {things: "foo"}}, {multi: true}) //update all documents in collection by pushing "foo" to the things array. Requires {multi: true} option

You can query an array on a value eg.

{ _id: 2, things: ["foo", "bar", "baz"]}
{ _id: 1, things: ["foo", "quaz", "zark"]}

db.foo.update({things: "foo"}, newVals) // this will update doc 1 and 2
db.foo.update({things: "bar"}, newVals) // this will update only doc 1


As well as update there is also findAndModify()



=================
Finding Documents
=================

db.foo.find(query, projection) - projection means which fields we want, if not supplied everything is returned


Comparison

db.foo.find({_id: {$gt: 3})
db.foo.find({_id: {$gt: 2, $lte: 5})
db.foo.find({_id: {$not: {$gt: 3}}})



db.animals.find({$tags: {$in: ['cute', 'ocean']}})
//get animal with either a tag cute or ocean


db.animals.find({$tags: {$all: ['cute', 'ocean']}})
// get animals which are both cute and in the ocean



"Dot" notation - digging deeper into objects - kinda like JS dots



db.animals.find({"info.canFly": true})

will find animals with an info field which has property canFly which is set to true. 
Doesn't matter if some objects don't have info or their info doens't contain a canFly field


ALWAYS USE DOT notation
do not do .find({info: {canFly:true, type:"bird"}}).

This would only match the subdocument exactly as it is, for example only if those fields appear in that order, with no other fields.
The above query would only find docs whos info document is EXACTLY {canFly:true, type:"bird"}


Dot notation should be used instead for drilling down

db.animals.find({"info.canFly": true, "info.type": "bird"})

matching null

db.animals.find({"info.canFly": null}) // returns docs where info.canFly is null OR not present

If you want to check for presence of a field, you can use $exists



projection examples

_id is always included unless explicitly excluded

{_id: 1} // return only id
{_id: 1, name: 1} // return id and name
{name: 0 } // return all fields but name



======
Cursor
======

What happens when you send a query to the mongo server?

the query might contain many many documents, potentially more than you could even keep in memory

Mongo uses a cursor to manage this. It will return a cursor which gives you a batch of documents

the application (or mongo shell) will take as many batches as they want, then when done inform the server to close the cursor




var c = db.animals.find({}) {name: 1});

c.size() - returns 6
c.hasNext()
c.forEach(d => print(d.name))

its more like a stream than a loop. If you call forEach then subsequently call hasNext it will return false.
Its iterable once


db.animals.find({}, {name: 1}).sort({name: 1}) //sort by name ascending (-1 for descending)


db.animals.find({}, {_id: 1}).sort({name: 1}) // Sort by name even though we aren't returning name. This is possible because sorting is done in the mongo server



We can sort on a sub property e.g info.type, and we can sort by multiple fields

db.animals.find({}).sort({"info.type": 1, "name": 1}) // sort by info.type, and then by name


query.limit(3) // return first 3 (or as many as present if fewer than 3)


query.skip(10).limit(10) // skip 10, show next 10


f you use findOne() you will be returned a record, rather than a cursor